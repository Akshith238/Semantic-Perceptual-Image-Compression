{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49eb78df-ff5b-4f23-b2d7-8ec0a66c85f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Reshape, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from skimage.draw import random_shapes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate synthetic dataset\n",
    "num_samples = 1000\n",
    "image_size = 64\n",
    "num_classes = 2\n",
    "\n",
    "images = []\n",
    "saliency_maps = []\n",
    "\n",
    "for _ in range(num_samples):\n",
    "    # Generate random shape\n",
    "    image, _ = random_shapes((image_size, image_size), max_shapes=1, shape='rectangle')\n",
    "\n",
    "    # Generate random saliency map (rectangle)\n",
    "    mask = np.zeros((image_size, image_size))\n",
    "    x, y = np.random.randint(5, 59, size=2)  # Random position for the rectangle\n",
    "    width, height = np.random.randint(10, 40, size=2)  # Random size for the rectangle\n",
    "    mask[x:x+width, y:y+height] = 1\n",
    "\n",
    "    images.append(image)\n",
    "    saliency_maps.append(mask)\n",
    "\n",
    "images = np.array(images)\n",
    "saliency_maps = np.array(saliency_maps)\n",
    "\n",
    "# Define the CNN architecture\n",
    "input_shape = (image_size, image_size, 3)  # Input shape for images\n",
    "input_mask_shape = (image_size, image_size, 1)  # Input shape for masks\n",
    "\n",
    "# Encoder\n",
    "input_img = Input(shape=input_shape)\n",
    "input_mask = Input(shape=input_mask_shape)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "encoded = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "# Decoder\n",
    "x = Dense(128, activation='relu')(encoded)\n",
    "x = Reshape((8, 8, 2))(x)  # Adjust the shape based on the encoded size\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# Create the model\n",
    "autoencoder = Model([input_img, input_mask], decoded)\n",
    "\n",
    "# Compile the model\n",
    "autoencoder.compile(optimizer=Adam(lr=0.001), loss=MeanSquaredError())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0c2b29f-3c7c-4d95-8cd2-c1dad529a7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\akshi\\anaconda3\\envs\\spic\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\akshi\\anaconda3\\envs\\spic\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\akshi\\anaconda3\\envs\\spic\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\akshi\\anaconda3\\envs\\spic\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\akshi\\anaconda3\\envs\\spic\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\akshi\\anaconda3\\envs\\spic\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 216, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"model\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(32, 64, 64, 3) dtype=uint8>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaliency_maps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\spic\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filelew__ajf.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\akshi\\anaconda3\\envs\\spic\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\akshi\\anaconda3\\envs\\spic\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\akshi\\anaconda3\\envs\\spic\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\akshi\\anaconda3\\envs\\spic\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\akshi\\anaconda3\\envs\\spic\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\akshi\\anaconda3\\envs\\spic\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 216, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"model\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(32, 64, 64, 3) dtype=uint8>]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "autoencoder.fit(images, saliency_maps, epochs=50, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244a62e9-2de7-4cb8-8bb1-b004960a61bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "sample_index = 0  # Change this to test different samples\n",
    "decoded_maps = autoencoder.predict([images, saliency_maps])\n",
    "decoded_map = decoded_maps[sample_index]\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(images[sample_index])\n",
    "plt.title('Original Image')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(saliency_maps[sample_index][:, :, 0], cmap='gray')\n",
    "plt.title('Original Saliency Map')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(decoded_map[:, :, 0], cmap='gray')\n",
    "plt.title('Decoded Saliency Map')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spic",
   "language": "python",
   "name": "spic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
